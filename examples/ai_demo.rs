use std::env;
use tokio;

use galaxy_flow::ai::{AiClient, AiConfig};

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // æ£€æŸ¥å¯†é’¥
    if env::var("OPENAI_API_KEY").is_err() {
        println!("âŒ è¯·è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY");
        println!("ç¤ºä¾‹: export OPENAI_API_KEY='ä½ çš„å¯†é’¥'");
        return Ok(());
    }

    println!("ğŸš€ GXL AI åŸç”Ÿå·¥ä½œæµæ¼”ç¤ºå¯åŠ¨...");

    // åŠ è½½é…ç½®
    let config = AiConfig::load()?;
    let client = AiClient::new(config)?;

    println!("âœ… AIå®¢æˆ·ç«¯å·²å¯åŠ¨");
    println!("ğŸ¯ å¯ç”¨provider: {:?}", client.available_providers());

    // æµ‹è¯•AIèƒ½åŠ›
    let test_prompt = "Explain what the future of AI-assisted coding looks like in one sentence.";

    match client
        .smart_request(
            galaxy_flow::ai::capabilities::AiCapability::Generate,
            test_prompt,
        )
        .await
    {
        Ok(response) => {
            println!("ğŸ‰ AIå“åº”:");
            println!("{}", response.content);
            println!(
                "\næ¨¡å‹: {}, tokens: {}",
                response.model, response.usage.total_tokens
            );
            if let Some(cost) = response.usage.estimated_cost {
                println!("ğŸ’° é¢„ä¼°æˆæœ¬: ${:.4}", cost);
            }
        }
        Err(e) => {
            println!("âŒ è¯·æ±‚å¤±è´¥: {}", e);
        }
    }

    Ok(())
}
