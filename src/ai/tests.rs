#[cfg(test)]
mod tests {
    use crate::ai::{
        capabilities::AiDevCapability,
        client::AiClient,
        provider::{AiProvider, AiRequestBuilder},
        providers::{mock::MockProvider, openai::OpenAiProvider},
        AiConfig,
    };

    use std::error::Error;

    // ğŸ¯ å®é™…å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹

    #[tokio::test]
    async fn test_mock_provider_workflow() -> Result<(), Box<dyn Error>> {
        println!("ğŸ”§ Testing Mock Provider...");

        let provider = MockProvider::new();

        let request = AiRequestBuilder::new()
            .model("mock-model")
            .system_prompt("ä½ æ˜¯ä¸€ä¸ªRustå·¥ç¨‹å¸ˆ")
            .user_prompt("ç”¨ä¸€å¥è¯è§£é‡Šæ‰€æœ‰æƒæœºåˆ¶")
            .capability(AiDevCapability::Explain)
            .max_tokens(50)
            .build();

        let response = provider.send_request(&request).await?;

        assert!(!response.content.is_empty());
        println!("âœ… Mock Response: {}", response.content);
        Ok(())
    }

    #[tokio::test]
    async fn test_openai_integration_if_available() -> Result<(), Box<dyn Error>> {
        println!("ğŸ” Testing OpenAI Integration...");

        if let Ok(api_key) = std::env::var("OPENAI_API_KEY") {
            let provider = OpenAiProvider::new(api_key);

            let request = AiRequestBuilder::new()
                .model("gpt-4o-mini")
                .system_prompt("ä½ æ˜¯ä¸€ä¸ªç¼–ç¨‹åŠ©æ‰‹")
                .user_prompt("ç”¨ä¸€å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯é›¶ä¾èµ–")
                .capability(AiDevCapability::Suggest)
                .max_tokens(75)
                .temperature(0.7)
                .build();

            let response = provider.send_request(&request).await?;

            assert!(!response.content.is_empty());
            println!("ğŸŸ¢ OpenAI Response: {}", response.content);
        } else {
            println!("âš ï¸ Skipping OpenAI - no API key");
        }

        Ok(())
    }

    #[tokio::test]
    async fn test_ai_client_e2e() -> Result<(), Box<dyn Error>> {
        println!("ğŸ¯ Testing AI Client End-to-End...");

        let config = AiConfig::load()?;
        let client = AiClient::new(config)?;

        // Test 1: Basic request
        let response = client
            .smart_request(
                AiDevCapability::Generate,
                "å†™ä¸€ä¸ªç®€å•çš„Hello World Rustç¨‹åº",
            )
            .await?;

        assert!(!response.content.is_empty());
        println!("ğŸ³ Generated: {}", response.content.trim());

        // Test 2: Smart commit
        let commit = client
            .smart_commit("ä¿®å¤äº†è¾“å…¥éªŒè¯é€»è¾‘ï¼Œæ·»åŠ äº†è¾¹ç•Œæ£€æŸ¥")
            .await?;

        assert!(!commit.content.is_empty());
        assert!(commit.content.len() <= 75);
        println!("ğŸ“ Smart commit: {}", commit.content);

        // Test 3: Code review
        let review = client
            .code_review("fn divide(a:i32, b:i32) -> i32 { a / b }", "math_utils.rs")
            .await?;

        assert!(!review.content.is_empty());
        println!("ğŸ” Code review: {}", review.content);

        Ok(())
    }

    #[test]
    fn test_module_compilation() {
        // Basic compilation test
        assert!(true);
    }

    #[test]
    fn test_capability_models() {
        assert_eq!(AiDevCapability::Analyze.recommended_model(), "gpt-4o-mini");
        assert_eq!(AiDevCapability::Generate.recommended_model(), "gpt-4o");
        assert_eq!(
            AiDevCapability::Review.recommended_model(),
            "claude-3-5-sonnet"
        );
        assert_eq!(AiDevCapability::Commit.recommended_model(), "gpt-4o-mini");
    }

    #[tokio::test]
    async fn test_zero_config_mode() -> Result<(), Box<dyn Error>> {
        // Test the core functionality works even in "zero-config" mode
        let config = AiConfig::default();
        let client = AiClient::new(config)?;

        let providers = client.available_providers();
        assert!(!providers.is_empty());

        println!("âœ… Available providers: {:?}", providers);
        Ok(())
    }

    // ğŸš€ å®é™…è¿è¡Œå‘½ä»¤ï¼š
    // cargo test --test ai_tests -- --nocapture
    // OPENAI_API_KEY=your_key cargo test -- --test-threads=1
    // ./test_openai.sh
}
