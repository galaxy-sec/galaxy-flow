use clap::{Parser, Subcommand};
use std::env;
use tokio;

use galaxy_flow::ai::{AiClient, AiConfig, AiCapability};

#[derive(Parser)]
#[command(name = "gx-ai", version = "1.0", about = "GXL AI-Native å·¥ä½œæµå¼•æ“")]
struct Cli {
    #[command(subcommand)]
    command: Commands,
}

#[derive(Subcommand)]
enum Commands {
    /// æ™ºèƒ½Gitæäº¤ - ç†è§£ä»£ç å˜æ›´å¹¶ç”Ÿæˆæäº¤ä¿¡æ¯
    SmartCommit {
        /// è‡ªåŠ¨æ¨¡å¼ï¼Œæ— éœ€ç¡®è®¤
        #[arg(long)]
        auto: bool,

        /// å¹²è·‘æ¨¡å¼ï¼Œä»…æ˜¾ç¤ºå»ºè®®ä¿¡æ¯ï¼Œä¸å®é™…æäº¤
        #[arg(long)]
        dry_run: bool,
    },

    /// ä»£ç å®¡å®¡æŸ¥ - æ™ºèƒ½åˆ†æå˜æ›´ä»£ç è´¨é‡
    CodeReview {
        /// æŒ‡å®šç›®æ ‡æ–‡ä»¶
        #[arg(short, long)]
        files: Vec<String>,
    },

    /// AIèƒ½åŠ›æµ‹è¯• - å¿«é€Ÿæµ‹è¯•AIè¿æ¥
    Test {
        /// æŒ‡å®šæµ‹è¯•æ¶ˆæ¯
        #[arg(short, long, default_value = "Hello from GXL")]
        message: String,

        /// æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹
        #[arg(short, long)]
        model: Option<String>,
    },

    /// åˆ—å‡ºå¯ç”¨AIæä¾›å•†å’Œæ¨¡å‹
    List,

    /// ç”Ÿæˆé¡¹ç›®CHANGELOG
    Changelog,
}

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // æ£€æŸ¥åŸºæœ¬ç¯å¢ƒ
    if env::var("OPENAI_API_KEY").is_err() && env::var("CLAUDE_API_KEY").is_err() {
        println!("âŒ éœ€è¦è®¾ç½®è‡³å°‘ä¸€ä¸ªAIå¯†é’¥:");
        println!("  OPENAI_API_KEY  æˆ–è€…  CLAUDE_API_KEY");
        println!("ğŸ¯ ç¤ºä¾‹: export OPENAI_API_KEY='your-key-here'");
        return Ok(());
    }

    println!("ğŸš€ GXL AI-Native å¼•æ“å¯åŠ¨...");

    // åˆå§‹åŒ–AIå®¢æˆ·ç«¯
    let config = AiConfig::load()?;
    let client = AiClient::new(config)?;

    let cli = Cli::parse();

    match cli.command {
        Commands::SmartCommit { auto, dry_run } => {
            smart_commit(auto, dry_run).await?;
        }
        Commands::CodeReview { files } => {
            code_review(files).await?;
        }
        Commands::Test { message, model } => {
            test_ai(client, message, model).await?;
        }
        Commands::List => {
            list_models(client).await?;
        }
        Commands::Changelog => {
            generate_changelog().await?;
        }
    }

    Ok(())
}

async fn smart_commit(auto: bool, dry_run: bool) -> Result<(), Box<dyn std::error::Error>> {
    use galaxy_flow::git_ai::SmartCommitFlow;

    println!("ğŸ¯ å¯åŠ¨æ™ºèƒ½Gitæäº¤...");

    let config = AiConfig::load()?;
    let client = AiClient::new(config)?;

    let flow = SmartCommitFlow::new(client, auto);

    if dry_run {
        println!("ğŸƒ [{DRY RUN MODE}] - ä»…æ˜¾ç¤ºå»ºè®®ï¼Œä¸æ‰§è¡Œæäº¤");
    }

    flow.execute().await?;
    Ok(())
}

async fn code_review(files: Vec<String>) -> Result<(), Box<dyn std::error::Error>> {
    let config = AiConfig::load()?;
    let client = AiClient::new(config)?;

    println!("ğŸ” å¼€å§‹ä»£ç å®¡æŸ¥...");

    // ç®€å•çš„ä»£ç å®¡æŸ¥ç¤ºä¾‹
    for file in files.iter().take(3) { // æœ€å¤š3ä¸ªæ–‡ä»¶
        if let Ok(content) = std::fs::read_to_string(file) {
            let response = client
                .smart_request(AiCapability::Review, &format!("å®¡æŸ¥æ–‡ä»¶ {} çš„ä»£ç :\n{}", file, content))
                .await?;

            println!("ğŸ“„ æ–‡ä»¶ {} çš„å®¡æŸ¥ç»“æœ:", file);
            println!("{}", response.content);
            println!("-------------------");
        } else {
            println!("âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶: {}", file);
        }
    }

    if files.is_empty() {
        println!("è¯·æŒ‡å®šè¦å®¡æŸ¥çš„æ–‡ä»¶ï¼Œä¾‹å¦‚: gx-ai code-review --files main.rs utils.rs");
    }

    Ok(())
}

async fn test_ai(mut client: AiClient, message: String, model: Option<String>) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ§ª AIè¿æ¥æµ‹è¯•...");

    let test_prompt = format!("ç®€è¦å›ç­”ï¼š{}", message);

    let response = if let Some(model_name) = model {
        let request = galaxy_flow::ai::AiRequest::builder()
            .model(model_name)
            .user_prompt(test_prompt)
            .build();
        client.send_request(request).await?
    } else {
        client.smart_request(AiCapability::Suggest, &test_prompt).await?
    };

    println!("ğŸ¯ å“åº”å†…å®¹:");
    println!("{}", response.content);
    println!("ğŸ’¡ ä½¿ç”¨æ¨¡å‹: {}", response.model);
    if let Some(cost) = response.usage.estimated_cost {
        println!("ğŸ’° æˆæœ¬: ${:.4}", cost);
    }

    Ok(())
}

async fn list_models(client: AiClient) -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ” å¯ç”¨AIæä¾›å•†å’Œæ¨¡å‹:");

    for provider in client.available_providers() {
        println!("ğŸ“Š {}:", provider);
    }

    println!("\nğŸ› ï¸ å½“å‰é…ç½®:");
    println!("  æ”¯æŒ: OpenAI, Anthropic, Ollama");
    println!("  ä½¿ç”¨:è®¾ç½®OPENAI_API_KEYæˆ–CLAUDE_API_KEY");
    Ok(())
}

async fn generate_changelog() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ”– Changelogç”ŸæˆåŠŸèƒ½å¼€å‘ä¸­...");
    println!("æ•¬è¯·æœŸå¾…æ™ºèƒ½æ›´æ–°æ—¥å¿—ç”Ÿæˆï¼");
    Ok(())
}
+            .build();
+        client.send_request(request).
